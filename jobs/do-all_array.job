#!/bin/bash

#SBATCH --partition=gpu_titanrtx_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=DoAllNLI
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=06:00:00
#SBATCH --mem=32000M
#SBATCH --array=4-4%2
#SBATCH --output=jobs/slurm_output/do-all_%A_%a.out

module purge
module load 2021
module load Anaconda3/2021.05

ARRAY_FILE=$HOME/NLI2/jobs/model_types.txt

cd $HOME/NLI2/
source activate nli2

# srun python -u nli/train.py   $(head -$SLURM_ARRAY_TASK_ID $ARRAY_FILE | tail -1)
srun python -u nli/eval.py    $(head -$SLURM_ARRAY_TASK_ID $ARRAY_FILE | tail -1)
srun python -u nli/results.py $(head -$SLURM_ARRAY_TASK_ID $ARRAY_FILE | tail -1)
